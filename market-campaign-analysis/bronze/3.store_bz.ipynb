{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad5a75cb-8ea1-4ab3-a452-ad6bfbc1ba42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run\n",
    "\"/Workspace/Users/aavishkarm@outlook.com/Development/projects/databricks_projects/market-campaign-analysis/setup/0.common_var\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2128f73-10c5-402d-8da4-db2c30c5529f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def readStore():\n",
    "    from pyspark.sql.functions import input_file_name, current_timestamp\n",
    "    return spark.read.format('json')\\\n",
    "                     .option(\"multiline\", \"true\")\\\n",
    "                     .load(raw_store_loc)\\\n",
    "                     .withColumn(\"input_file\", input_file_name())\\\n",
    "                     .withColumn(\"load_time\", current_timestamp())\n",
    "\n",
    "def saveStoreBz(df):\n",
    "    df.write.mode(\"overwrite\").saveAsTable(\"store_bz\")\n",
    "    print(\"\\nsaved store bz data to table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9bf9a2e4-e51c-4e16-8b09-ecac11d516b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def runStoreBzProcess():\n",
    "    print(\"\\nstarted store bronze loading\")\n",
    "    df_store = readStore()\n",
    "    saveStoreBz(df_store)\n",
    "    print(\"\\ncompleted store bronze loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2bee8c39-887c-42c6-b034-396395a6e76c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "runStoreBzProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b092c80b-6cde-4662-9186-1dc9bbbcbdcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select * from store_bz"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8846439338856000,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "3.store_bz",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
